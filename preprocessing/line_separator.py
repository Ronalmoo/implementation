import sys, fileinput, re
from nltk.tokenize import sent_tokenize


if __name__ == "__main__":
    for line in fileinput.input('input.ko.txt'):
        if line.strip() != "":
            line = re.sub(r'([a-z])\.([A-Z])', r'\1. \2', line.strip())

            sentences = sent_tokenize(line.strip())
            for s in sentences:
                if s != "":
                    sys.stdout.write(s + '\n')
